{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training code for Wasserstein INN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T23:09:23.222217Z",
     "start_time": "2017-08-24T23:09:23.219296Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'Long Jin, Weijian Xu, and Kwonjoon Lee'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Libraries and Functions\n",
    "\n",
    "This section imports or creates a series of functions to support model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library\n",
    "\n",
    "This section imports all needed libraries. All libraries are either built-in or from PyPI. You may need to use `pip` to install missing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T23:09:24.270892Z",
     "start_time": "2017-08-24T23:09:23.229700Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from utils import *\n",
    "from numpy import inf\n",
    "\n",
    "# Display the versions for libraries. In my environment, they are\n",
    "#     Python version: 2.7.13 |Anaconda custom (64-bit)| (default, Sep 30 2017, 18:12:43)\n",
    "#     [GCC 7.2.0]\n",
    "#     SciPy version: 0.19.1\n",
    "#     NumPy version: 1.14.2\n",
    "#     TensorFlow version: 1.7.0\n",
    "#     Scikit-learn version: 0.19.0\n",
    "print('Python version: {}'.format(sys.version))\n",
    "print('SciPy version: {}'.format(scipy.__version__))\n",
    "print('NumPy version: {}'.format(np.__version__))\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "print('Scikit-learn version: {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T23:09:24.403679Z",
     "start_time": "2017-08-24T23:09:24.272186Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.deconv2d\n",
    "import tflib.save_images\n",
    "import tflib.small_imagenet\n",
    "import tflib.ops.layernorm\n",
    "import tflib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch size. It should be a squared number.\n",
    "batch_size = 100\n",
    "# Number of cascades in WINN.\n",
    "cascades = 4\n",
    "# Number of iterations per cascade\n",
    "# In Algorithm 1 of the paper, we wrote we iterate while W_t has not converged.\n",
    "# In practice, we find that 100 iterations is sufficient for convergence.\n",
    "iterations_per_cascade = 100\n",
    "# hyperparameter k in the Algorithm 1\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Working Directory\n",
    "\n",
    "WARNING: ~6GB of disk space is required for 1 cascade training\n",
    "\n",
    "data/evaluation: synthesized pseudo-negative samples during test time (will be created when you run test code)\n",
    "\n",
    "data/negative: pseudo-negative samples of all iterations/cascades\n",
    "\n",
    "data/intermediate: images showing one batch or training samples and pseudo-negative sample per iteration\n",
    "\n",
    "data/model: trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T23:09:24.620184Z",
     "start_time": "2017-08-24T23:09:24.513586Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Root directory of data directory. Customize it when using another directory.\n",
    "# e.g. \"./\"\n",
    "data_dir_root = \"/mnt/cube/kwl042/church_release_candidate_3\"\n",
    "# Path of data directory.\n",
    "data_dir_path = os.path.join(data_dir_root, \"data\")\n",
    "\n",
    "# Create a series of directories to contain the dataset.\n",
    "mkdir_if_not_exists(data_dir_root)\n",
    "mkdir_if_not_exists(data_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataset\n",
    "\n",
    "Path of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T23:09:24.645855Z",
     "start_time": "2017-08-24T23:09:24.622618Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path of training images directory.\n",
    "training_images_dir_path = \"/mnt/cube/kwl042/church/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "This section focuses on building the model for WINN. It contains layers and discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "This subsection contains all layers used in WINN model. E.g. convolutional layer, linear layer and batch normalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def swish(z):\n",
    "    return z * tf.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T23:09:24.764990Z",
     "start_time": "2017-08-24T23:09:24.757192Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Normalize(name, axes, inputs):\n",
    "    return lib.ops.layernorm.Layernorm(name,[1,2,3],inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T23:09:24.783827Z",
     "start_time": "2017-08-24T23:09:24.766181Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvMeanPool(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
    "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, inputs, he_init=he_init, biases=biases)\n",
    "    output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "    return output\n",
    "\n",
    "def MeanPoolConv(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
    "    output = inputs\n",
    "    output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, output, he_init=he_init, biases=biases)\n",
    "    return output\n",
    "\n",
    "def UpsampleConv(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
    "    output = inputs\n",
    "    output = tf.concat([output, output, output, output], axis=1)\n",
    "    output = tf.transpose(output, [0,2,3,1])\n",
    "    output = tf.depth_to_space(output, 2)\n",
    "    output = tf.transpose(output, [0,3,1,2])\n",
    "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, output, he_init=he_init, biases=biases)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "This subsection builds the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T23:09:24.793436Z",
     "start_time": "2017-08-24T23:09:24.784825Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GoodDiscriminator(inputs, dim=64, nonlinearity = swish, bn = True, reuse = False):\n",
    "    output = tf.reshape(tf.transpose(inputs, [0, 3, 1, 2]), [-1, 3, 64, 64])\n",
    "\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "    \n",
    "    with tf.variable_scope(\"layers\", reuse = reuse):\n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.1', 3, 32, 3, output, stride=1, he_init=False)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.2', 32, 64, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN2', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "        ### output: 64 channels x 32 x 32\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.3', 64, 64, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN3', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.4', 64, 128, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN4', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "        ### output: 128 channels x 16 x 16\n",
    "\n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.5', 128, 128, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN5', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.6', 128, 256, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN6', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "        ### output: 256 channels x 8 x 8\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.7', 256, 256, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN7', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.8', 256, 512, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN8', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "        ### output: 512 channels x 4 x 4\n",
    "        \n",
    "        output = tf.reshape(output, [-1, 4*4*512])\n",
    "        output = lib.ops.linear.Linear('Discriminator.Output', 4*4*512, 1, output)\n",
    "\n",
    "        lib.ops.conv2d.unset_weights_stdev()\n",
    "        lib.ops.deconv2d.unset_weights_stdev()\n",
    "        lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "    return tf.reshape(output, [-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Provider\n",
    "\n",
    "This subsection builds the networks that gives initial pseudo-negatives (Appendix E)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NoiseProvider(n_samples, noise=None, dim=64):\n",
    "    lib.ops.conv2d.set_weights_stdev(0.1)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.1)\n",
    "    lib.ops.linear.set_weights_stdev(0.1)\n",
    "    with tf.variable_scope(\"layers_np\", reuse = False):\n",
    "        output = noise\n",
    "        output = lib.ops.conv2d.Conv2D('NoiseProvider.2', 8*dim, 4*dim, 5, output, stride=1)\n",
    "        output = tf.transpose(output, [0, 2, 3, 1])\n",
    "        output = tf.image.resize_images(output, [8, 8], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        output = tf.transpose(output, [0, 3, 1, 2])\n",
    "        output = Normalize('NoiseProvider.BN2', [0,2,3], output)\n",
    "\n",
    "        output = lib.ops.conv2d.Conv2D('NoiseProvider.3', 4*dim, 2*dim, 5, output, stride=1)\n",
    "        output = tf.transpose(output, [0, 2, 3, 1])\n",
    "        output = tf.image.resize_images(output, [16, 16], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        output = tf.transpose(output, [0, 3, 1, 2])\n",
    "        output = Normalize('NoiseProvider.BN3', [0,2,3], output)\n",
    "\n",
    "        output = lib.ops.conv2d.Conv2D('NoiseProvider.4', 2*dim, dim, 5, output, stride=1)\n",
    "        output = tf.transpose(output, [0, 2, 3, 1])\n",
    "        output = tf.image.resize_images(output, [32, 32], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        output = tf.transpose(output, [0, 3, 1, 2])\n",
    "        output = Normalize('NoiseProvider.BN4', [0,2,3], output)\n",
    "\n",
    "        output = lib.ops.conv2d.Conv2D('NoiseProvider.5', dim, 3, 5, output, stride=1)\n",
    "        output = tf.transpose(output, [0, 2, 3, 1])\n",
    "        output = tf.image.resize_images(output, [64, 64], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        output = tf.transpose(output, [0, 3, 1, 2])\n",
    "\n",
    "        lib.ops.conv2d.unset_weights_stdev()\n",
    "        lib.ops.deconv2d.unset_weights_stdev()\n",
    "        lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "\n",
    "This subsection builds the WINN's discriminator and sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T23:09:24.879723Z",
     "start_time": "2017-08-24T23:09:24.805442Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network(batch_shape, LAMBDA=10.0):\n",
    "    '''\n",
    "    Build a network for WINN.\n",
    "        batch_shape: Shape of a mini-batch in classification-step and synthesis-step.\n",
    "                     The format is [batch size, height, width, channels].\n",
    "        LAMBDA: the weight for the gradient penalty term\n",
    "    Return loss, trainable variables, labels and images in discriminator and \n",
    "    sampler, plus checkpoint saver. \n",
    "    '''\n",
    "\n",
    "    # Fetch batch shape.\n",
    "    [batch_size, height, width, channels] = batch_shape\n",
    "    \n",
    "    half_b_size = batch_size / 2\n",
    "    \n",
    "    # Placeholder for images and labels.\n",
    "    D_pos_images = tf.placeholder(dtype = tf.float32, \n",
    "                              shape = [half_b_size, height, width, channels], \n",
    "                              name = 'D_pos_images')\n",
    "    D_neg_images = tf.placeholder(dtype = tf.float32, \n",
    "                              shape = [half_b_size, height, width, channels], \n",
    "                              name = 'D_neg_images')\n",
    "    \n",
    "    # Variable, placeholder and assign operator for multiple sampled images.\n",
    "    S_images = tf.Variable(\n",
    "        # Use uniform distribution Unif(-1, 1) to initialize.\n",
    "        # This initialization doesn't matter.\n",
    "        # It will be substituted by S_images_op.\n",
    "        np.random.uniform(low = -1.0,\n",
    "                          high = 1.0, \n",
    "                          size = [batch_size, height, width, channels]\n",
    "        ).astype('float32'), \n",
    "        name='S_images'\n",
    "    )\n",
    "    S_images_placeholder = tf.placeholder(dtype = S_images.dtype, \n",
    "                                          shape = S_images.get_shape())\n",
    "    S_images_op = S_images.assign(S_images_placeholder)\n",
    "\n",
    "    # Build a discriminator used in classification-step\n",
    "    D_pos_logits = GoodDiscriminator(D_pos_images, reuse = False)\n",
    "    D_neg_logits = GoodDiscriminator(D_neg_images, reuse = True)\n",
    "    D_loss = tf.reduce_mean(D_neg_logits - D_pos_logits)\n",
    "    D_pos_loss = tf.reduce_mean(D_pos_logits)\n",
    "    epsilon = tf.random_uniform([half_b_size, 1, 1, 1], 0.0, 1.0)\n",
    "    # Dirty hack to tile the tensor\n",
    "    epsilon = epsilon + tf.zeros(D_pos_images.shape, dtype=epsilon.dtype)\n",
    "    x_hat = epsilon * D_pos_images + (1 - epsilon) * D_neg_images\n",
    "    d_hat = GoodDiscriminator(x_hat, reuse = True)\n",
    "    \n",
    "    ddx = tf.gradients(d_hat, x_hat)[0]\n",
    "    ddx = tf.sqrt(tf.reduce_sum(tf.square(ddx), axis=[1, 2, 3]))\n",
    "    ddx = tf.reduce_mean(tf.square(ddx - 1.0) * LAMBDA)\n",
    "    D_loss += ddx\n",
    "    \n",
    "    # We need to store these values as they will be used for determining early-stopping threshold in testing stage\n",
    "    D_pos_loss_min = tf.Variable(0.0, name='D_pos_loss_min')\n",
    "    D_pos_loss_max = tf.Variable(0.0, name='D_pos_loss_max')\n",
    "    \n",
    "    D_pos_loss_min_placeholder = tf.placeholder(dtype = D_pos_loss_min.dtype, \n",
    "                                          shape = D_pos_loss_min.get_shape())\n",
    "    D_pos_loss_max_placeholder = tf.placeholder(dtype = D_pos_loss_max.dtype, \n",
    "                                          shape = D_pos_loss_max.get_shape())\n",
    "    D_pos_loss_min_op = D_pos_loss_min.assign(D_pos_loss_min_placeholder)\n",
    "    D_pos_loss_max_op = D_pos_loss_max.assign(D_pos_loss_max_placeholder)\n",
    "\n",
    "    # Build a sampler used in synthesis-step\n",
    "    S_logits = GoodDiscriminator(S_images, reuse = True)\n",
    "    S_loss = tf.reduce_mean(S_logits)\n",
    "\n",
    "    # Variable, placeholder and assign operator for multiple generated images.\n",
    "    small_noise = tf.Variable(\n",
    "        np.random.uniform(low = -1.0,\n",
    "                          high = 1.0, \n",
    "                          size = [batch_size, 512, 4, 4]\n",
    "        ).astype('float32'),\n",
    "        name='small_noise'\n",
    "    )\n",
    "    small_noise_placeholder = tf.placeholder(dtype = small_noise.dtype, \n",
    "                                          shape = small_noise.get_shape())\n",
    "    small_noise_op = small_noise.assign(small_noise_placeholder)\n",
    "    \n",
    "    big_noise = NoiseProvider(100, noise=small_noise, dim=64)\n",
    "    # Variables to train.\n",
    "    trainable_vars = tf.trainable_variables()\n",
    "    D_vars = [var for var in trainable_vars if 'layers' in var.name]\n",
    "    S_vars = [var for var in trainable_vars if 'S_images' in var.name]\n",
    "    \n",
    "    # Checkpoint saver.\n",
    "    saver = tf.train.Saver(max_to_keep = 5000)\n",
    "    \n",
    "    return [D_loss, S_loss, D_vars, S_vars, \n",
    "            D_pos_images, D_neg_images, S_images, S_images_op, S_images_placeholder,\n",
    "            saver, D_pos_loss, D_pos_loss_min, D_pos_loss_max,\n",
    "            D_pos_loss_min_placeholder, D_pos_loss_max_placeholder,\n",
    "            D_pos_loss_min_op, D_pos_loss_max_op, \n",
    "            small_noise, small_noise_op, small_noise_placeholder, big_noise]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "This section focuses on model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From https://github.com/Mazecreator/tensorflow-hints/tree/master/maximize\n",
    "def maximize(optimizer, loss, **kwargs):\n",
    "      return optimizer.minimize(-loss, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T23:09:24.909398Z",
     "start_time": "2017-08-24T23:09:24.881376Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimizers(D_loss, S_loss, D_vars, S_vars):\n",
    "    '''\n",
    "    Get optimizers.\n",
    "        D_loss: Discriminator loss.\n",
    "        S_loss: Sampler loss.\n",
    "        D_vars: Variables to train in discriminator.\n",
    "        S_vars: Variable to train in sampler = image.\n",
    "    Return optimizer of discriminator and sampler, plus discriminator \n",
    "    learning rate, discriminator global steps and the initializer for sampler.\n",
    "    '''\n",
    "    \n",
    "    # Scope of discriminator optimizer.\n",
    "    with tf.variable_scope('D_optimizer'):\n",
    "        # Global count of step in discriminator and increment operator.\n",
    "        # It should not be trainable and should be adjusted by training process.\n",
    "        D_global_step = tf.Variable(initial_value = 0, trainable = False)\n",
    "        D_global_step_op = D_global_step.assign_add(1)\n",
    "        # Learning rate with exponential decay.\n",
    "        D_learning_rate = tf.train.exponential_decay(learning_rate = 0.0001,\n",
    "                                                     global_step = D_global_step,\n",
    "                                                     decay_steps = 100,\n",
    "                                                     decay_rate = 0.9,\n",
    "                                                     staircase = True)        \n",
    "        D_adam = tf.train.AdamOptimizer(learning_rate = D_learning_rate, beta1=0., beta2=0.9)\n",
    "        D_optimizer = D_adam.minimize(loss = D_loss, var_list = D_vars)\n",
    "        \n",
    "    # Scope of sampler optimizer.\n",
    "    with tf.variable_scope('S_optimizer'):\n",
    "        S_global_step = tf.Variable(initial_value = 0, trainable = False, name = 'S_step')\n",
    "        S_learning_rate = 0.01\n",
    "\n",
    "        S_adam = tf.train.AdamOptimizer(learning_rate = S_learning_rate, beta1 = 0.9)\n",
    "        S_optimizer = maximize(optimizer = S_adam, loss = S_loss, var_list = S_vars)\n",
    "        \n",
    "    # Variables of generator optimizer and initializer operator of that.\n",
    "    S_optimizer_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \n",
    "                                         scope = 'WINN/S_optimizer')\n",
    "    print (\"S_optimizer_vars\", S_optimizer_vars)\n",
    "    S_initializer_op = tf.variables_initializer(S_optimizer_vars)\n",
    "\n",
    "    # Variables of sampler optimizer and initializer operator of that.\n",
    "    print(S_optimizer_vars)\n",
    "\n",
    "    return [D_optimizer, S_optimizer, D_learning_rate, S_initializer_op, S_global_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-08-24T23:09:40.350Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(sess):\n",
    "    \"\"\"\n",
    "    Train the WINN model.\n",
    "        sess: Session.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set timer.\n",
    "    start_time = time.time()\n",
    "    \n",
    "    half_batch_size = batch_size // 2\n",
    "    sqrt_batch_size = int(np.sqrt(batch_size))\n",
    "\n",
    "    # Log file path.\n",
    "    log_file_path = os.path.join(data_dir_path, \"log.txt\")\n",
    "    # Prepare for root directory of model.\n",
    "    model_root = os.path.join(data_dir_path, \"model\")\n",
    "    mkdir_if_not_exists(model_root)\n",
    "    # Prepare for root directory of intermediate image.\n",
    "    intermediate_image_root = os.path.join(data_dir_path, \"intermediate\")\n",
    "    mkdir_if_not_exists(intermediate_image_root)\n",
    "    # Prepare for root directory of negative images.\n",
    "    neg_image_root = os.path.join(data_dir_path, \"negative\")\n",
    "    mkdir_if_not_exists(neg_image_root)\n",
    "        \n",
    "    ######################################################################\n",
    "    # Training stage 1: Load positive images.\n",
    "    ######################################################################\n",
    "    log(log_file_path,\n",
    "        \"Training stage 1: Load positive images...\")\n",
    "\n",
    "    # Path of all positive images and negative images. \n",
    "    # The following training_images_dir_path can be replaced. The image shape of\n",
    "    # positive and negative images are the same.\n",
    "    pos_all_images_path = get_images_path_in_directory(training_images_dir_path)\n",
    "    image_shape = get_image_shape(pos_all_images_path[0])\n",
    "\n",
    "    ######################################################################\n",
    "    # Training stage 2: Build network and initialize.\n",
    "    ######################################################################\n",
    "    log(log_file_path,\n",
    "        \"Training stage 2: Build network and initialize...\")\n",
    "    height, width, channels = image_shape\n",
    "    \n",
    "    # Build network.\n",
    "    [D_loss, S_loss, D_vars, S_vars, \n",
    "     D_pos_images, D_neg_images, S_images, S_images_op, S_images_placeholder,\n",
    "     saver, D_pos_loss, D_pos_loss_min, D_pos_loss_max,\n",
    "     D_pos_loss_min_placeholder, D_pos_loss_max_placeholder,\n",
    "     D_pos_loss_min_op, D_pos_loss_max_op, \n",
    "     small_noise, small_noise_op, small_noise_placeholder, big_noise] = \\\n",
    "        build_network(batch_shape = [batch_size, height, width, channels])\n",
    "        \n",
    "    # Get optimizer.\n",
    "    [D_optimizer, S_optimizer, D_learning_rate, S_initializer_op, S_global_step] = \\\n",
    "        get_optimizers(D_loss = D_loss, S_loss = S_loss, \n",
    "                       D_vars = D_vars, S_vars = S_vars)\n",
    "        \n",
    "    # Show a list of global variables.\n",
    "    global_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='')\n",
    "    log(log_file_path, \"Global variables:\")\n",
    "    for i, var in enumerate(global_variables):\n",
    "        log(log_file_path, \"{0} {1}\".format(i, var.name))\n",
    "        \n",
    "    # Initialize all variables.\n",
    "    all_initializer_op = tf.global_variables_initializer()\n",
    "    sess.run(all_initializer_op)\n",
    "    \n",
    "    # Generate initial pseudo-negative images\n",
    "    # In fact, the name of image has format \n",
    "    #     {cascade}_{next iteration}_{i}.png\n",
    "    # where cascade means current cascade model, next iteration means\n",
    "    # next iteration of generator and discriminator training, and i means\n",
    "    # the index of images.\n",
    "    neg_image_path = os.path.join(neg_image_root, 'cascade_{0}_iteration_{1}_count_{2}.png')\n",
    "    neg_init_images_count = 10000\n",
    "    neg_init_images_path = [neg_image_path.format(0, 0, i) \\\n",
    "                            for i in range(neg_init_images_count)]\n",
    "    \n",
    "    S_iteration_count_of_batch = neg_init_images_count // batch_size\n",
    "    \n",
    "    for i in xrange(S_iteration_count_of_batch):             \n",
    "        small_noise_batch = np.random.uniform(low=-1.0, high=1.0, size=(100, 512, 4, 4))\n",
    "        sess.run(small_noise_op, {small_noise_placeholder: \n",
    "                       small_noise_batch})\n",
    "        np_noise_images = np.transpose(sess.run(big_noise), axes=[0, 2, 3, 1])\n",
    "\n",
    "        # Generate random images as negatives and save them.\n",
    "        for j in range(100):#, neg_init_image_path in enumerate(neg_init_images_path):\n",
    "            # Attention: Though it is called neg_image here, it has 4 dimensions,\n",
    "            #            that is, [1, height, width, channels], which is not a\n",
    "            #            pure single image, which is [height, width, channels].\n",
    "            #            So we still use save_unnormalized_images here instead of \n",
    "            #            save_unnormalized_image.\n",
    "            neg_image = np_noise_images[j].reshape(1, 64, 64, 3)\n",
    "            neg_image = neg_image - neg_image.min()\n",
    "            neg_image = neg_image / neg_image.max() * 255.0 \n",
    "            save_unnormalized_images(images = neg_image, \n",
    "                                     size = (1, 1), path = neg_init_images_path[batch_size * i + j])\n",
    "\n",
    "    neg_all_images_path = neg_init_images_path\n",
    "    \n",
    "    ######################################################\n",
    "    log(log_file_path,\n",
    "        \"Positive images {0}, negative images {1}, image shape {2}\".format(\n",
    "        len(pos_all_images_path), len(neg_all_images_path), image_shape))\n",
    "    \n",
    "    ######################################################################\n",
    "    # Training stage 3: Cascades training.\n",
    "    ######################################################################\n",
    "    log(log_file_path, \"Training stage 3: Cascades training...\")\n",
    "        \n",
    "    # One cascade means one new model.\n",
    "    # p_{W^n}^- <- [cascade n] <- [cascade n-1] <- ... <- [cascade 0] <- p_r \n",
    "    # where p_r means Uniform or Gaussian reference distribution \n",
    "    # and p_{W^n}^- means distribution of pseudo-negatives after n cascades.\n",
    "    # One cascade training consists multiple iterations (by default 100 iterations).\n",
    "    \n",
    "    # Prepare for the initial images to feed the generator. In fact, it is \n",
    "    # because we always use negative images in last cascade as the \"initial\"\n",
    "    # images to feed generator in all iterations of current cascade.\n",
    "    S_neg_last_cascade_images_path = copy.deepcopy(neg_all_images_path)\n",
    "    \n",
    "    for cascade in xrange(cascades):\n",
    "        ######################################################################\n",
    "        # Training stage 3.1: Iterations training.\n",
    "        ######################################################################\n",
    "        # One iteration means one time of discriminator training and one time\n",
    "        # of generator training. One iteration training may contain multiple\n",
    "        # batches for discriminator and generator training.\n",
    "        for iteration in xrange(iterations_per_cascade):\n",
    "            ######################################################################\n",
    "            # Training stage 3.1.1: Prepare images and labels for discriminator\n",
    "            # training.\n",
    "            ######################################################################\n",
    "            # Count of positive images to train in current iteration.\n",
    "            D_pos_iteration_images_count = min(iteration + 1, 5) * 1000 \\\n",
    "                // half_batch_size * half_batch_size\n",
    "            \n",
    "            if D_pos_iteration_images_count >= len(pos_all_images_path):\n",
    "                # When the number of all positive images is more than current\n",
    "                # iteration negative images, we allow duplicate images.\n",
    "                D_pos_iteration_images_path = np.random.choice(\n",
    "                    pos_all_images_path, \n",
    "                    size = D_pos_iteration_images_count, \n",
    "                    replace = True\n",
    "                ).tolist()\n",
    "            else:\n",
    "                # When the number of all positive images is less or equal than \n",
    "                # current iteration negative images, we require unique images.\n",
    "                D_pos_iteration_images_path = np.random.choice(\n",
    "                    pos_all_images_path, \n",
    "                    size = D_pos_iteration_images_count, \n",
    "                    replace = False\n",
    "                ).tolist()\n",
    "\n",
    "            # Here we consider the \"save all\" mode in Long Jin's code. This mode\n",
    "            # has different behaviors on discriminator and generator.\n",
    "            # 1) Discriminator.\n",
    "            #     We draw positive images from training dataset and the same\n",
    "            #     number of negative images from *all* pseudo-negative images in data/negative folder.\n",
    "            #     Every iteration of generator will add newly generated negative images\n",
    "            #     into all data/negative foler.\n",
    "            # 2) Generator.\n",
    "            #     We draw \"initial\" negative images in every iterations in current\n",
    "            #     cascade from part of generated negative images in last cascade.\n",
    "            #     More specificially, the part is the *last* iteration of last cascade.\n",
    "            D_neg_iteration_images_count = D_pos_iteration_images_count\n",
    "            D_neg_iteration_images_path = np.random.choice(\n",
    "                neg_all_images_path,\n",
    "                D_pos_iteration_images_count, \n",
    "                replace = True).tolist()\n",
    "                            \n",
    "            log(log_file_path,\n",
    "                   (\"Discriminator: Cascade {0}, iteration {1}, \" + \n",
    "                   \"all pos {2}, all neg {3}, \" + \n",
    "                   \"current iteration {4} (pos {5}, neg {6}), \" + \n",
    "                   \"learning rate {7}\").format(\n",
    "                       cascade, iteration, \n",
    "                       len(pos_all_images_path), len(neg_all_images_path), \n",
    "                       D_pos_iteration_images_count + D_neg_iteration_images_count, \n",
    "                       D_pos_iteration_images_count, D_neg_iteration_images_count, \n",
    "                       sess.run(D_learning_rate)\n",
    "                   ))\n",
    "            \n",
    "            ######################################################################\n",
    "            # Training stage 3.1.2: Train the discriminator.\n",
    "            ######################################################################\n",
    "            # Count of batch in discriminator training in current iteration. \n",
    "            D_iteration_count_of_batch = len(D_pos_iteration_images_path) // half_batch_size\n",
    "            \n",
    "            min_D_batch_pos_loss = inf\n",
    "            max_D_batch_pos_loss = -inf\n",
    "            \n",
    "            for nc in range(k):\n",
    "                for i in xrange(D_iteration_count_of_batch):\n",
    "                    # Load images for this batch in discriminator.\n",
    "                    D_pos_batch_images = [load_unnormalized_image(path) for path in\n",
    "                        D_pos_iteration_images_path[i * half_batch_size : (i + 1) * half_batch_size]]\n",
    "                    D_neg_batch_images = [load_unnormalized_image(path) for path in\n",
    "                        D_neg_iteration_images_path[i * half_batch_size : (i + 1) * half_batch_size]]\n",
    "                    # Normalize.\n",
    "                    D_pos_batch_images = normalize(np.array(D_pos_batch_images)).astype(np.float32)\n",
    "                    D_neg_batch_images = normalize(np.array(D_neg_batch_images)).astype(np.float32)\n",
    "\n",
    "                    sess.run(D_optimizer, \n",
    "                             feed_dict = {D_pos_images: D_pos_batch_images,\n",
    "                                          D_neg_images: D_neg_batch_images})\n",
    "                    if (nc == k - 1):\n",
    "                        # Positive samples' loss after training in current iteration.\n",
    "                        # It will be used as an early stopping threshold when we generate pseudo-negative samples\n",
    "                        D_batch_pos_loss = sess.run(D_pos_loss, \n",
    "                         feed_dict = {D_pos_images: D_pos_batch_images})\n",
    "                        if (D_batch_pos_loss < min_D_batch_pos_loss):\n",
    "                            min_D_batch_pos_loss = D_batch_pos_loss\n",
    "                        if (D_batch_pos_loss > max_D_batch_pos_loss):\n",
    "                            max_D_batch_pos_loss = D_batch_pos_loss\n",
    "                # Discriminator loss after training in current iteration.\n",
    "                D_last_batch_loss = sess.run(D_loss, \n",
    "                     feed_dict = {D_pos_images: D_pos_batch_images,\n",
    "                                  D_neg_images: D_neg_batch_images})\n",
    "                \n",
    "                log(log_file_path, \n",
    "                    \"Discriminator: Cascade {0}, iteration {1}, Critic {2}, time {3}, D_loss {4}, D_pos_loss {5}, {6}\".format(\n",
    "                    cascade, iteration, nc, time.time() - start_time, D_last_batch_loss, min_D_batch_pos_loss, max_D_batch_pos_loss))\n",
    "        \n",
    "            # Save last batch images in discriminator training.\n",
    "            D_intermediate_image_path = os.path.join(intermediate_image_root,\n",
    "                'D_cascade_{0}_iteration_{1}.png').format(cascade, iteration)\n",
    "            save_unnormalized_images(images = unnormalize(np.concatenate((D_pos_batch_images, \\\n",
    "                                                                          D_neg_batch_images), axis=0)), \n",
    "                                     size = (sqrt_batch_size, sqrt_batch_size), \n",
    "                                     path = D_intermediate_image_path)\n",
    "        \n",
    "            ######################################################################\n",
    "            # Training stage 3.1.3: Prepare images for generator training.\n",
    "            ######################################################################\n",
    "\n",
    "            # Load path of negative images in last cascade and shuffle.\n",
    "            S_neg_last_cascade_images_path = shuffle(S_neg_last_cascade_images_path)\n",
    "            # Attention again, the last cascade here does not mean all negative images\n",
    "            # produced in last cascade, but only negative images in last iteration of\n",
    "            # last cascade.\n",
    "\n",
    "            # Number of negative images to be generated in current iteration.\n",
    "            if iteration == iterations_per_cascade - 1:\n",
    "                # Generate more in last iteration of cascade.\n",
    "                S_neg_iteration_images_count = 10000\n",
    "            else:\n",
    "                S_neg_iteration_images_count = 1000\n",
    "            \n",
    "            S_neg_current_iteration_images_path = \\\n",
    "                [os.path.join(neg_image_root, 'cascade_{0}_iteration_{1}_count_{2}.png').format(\n",
    "                    cascade, iteration + 1, i) for i in xrange(\n",
    "                        S_neg_iteration_images_count)]\n",
    "            \n",
    "            log(log_file_path,\n",
    "                  (\"Sampler: Cascade {0}, iteration {1}, \" + \n",
    "                   \"current iteration neg {2}\").format(\n",
    "                   cascade, iteration, \n",
    "                   S_neg_iteration_images_count))\n",
    "                  \n",
    "            # Save early-stopping threshold in the model\n",
    "            if iteration == iterations_per_cascade - 1:\n",
    "                sess.run(D_pos_loss_min_op, {D_pos_loss_min_placeholder: \n",
    "                       min_D_batch_pos_loss})\n",
    "                sess.run(D_pos_loss_max_op, {D_pos_loss_max_placeholder: \n",
    "                       max_D_batch_pos_loss})\n",
    "\n",
    "            ######################################################################\n",
    "            # Training stage 3.1.3: Train the generator.\n",
    "            ######################################################################\n",
    "            # Count of batch in generator training in current iteration. \n",
    "            S_iteration_count_of_batch = S_neg_iteration_images_count // batch_size\n",
    "            for i in xrange(S_iteration_count_of_batch):\n",
    "                # Initializer the image in generator. However, it is strange because\n",
    "                # we will feed the S_images later. It is only needed if we want to\n",
    "                # generate images from noise. So we ignore it at first.\n",
    "                sess.run(S_initializer_op)\n",
    "                sess.run(S_global_step.initializer)\n",
    "                \n",
    "                # Load images from last cascade generated negative images.\n",
    "                # We mention it again, that is, in each iteration in current cascade, \n",
    "                # we will generate images based on last cascade, but not last iteration. \n",
    "                # It is quite a strange strategy.\n",
    "                S_neg_batch_images = [load_unnormalized_image(path) for path in\n",
    "                    S_neg_last_cascade_images_path[i * batch_size : \n",
    "                                                   (i + 1) * batch_size]]\n",
    "                # Normalize.\n",
    "                S_neg_batch_images = normalize(np.array(S_neg_batch_images)\n",
    "                                              ).astype(np.float32)\n",
    "                # Feed into generator.\n",
    "                sess.run(S_images_op, {S_images_placeholder: \n",
    "                                       S_neg_batch_images})\n",
    "\n",
    "                # Generating process. We may optimize images for several times\n",
    "                # to get good images. Early stopping is used here to accelerate.\n",
    "                thres_ = np.random.uniform(min_D_batch_pos_loss, max_D_batch_pos_loss)\n",
    "                count_of_optimizing_steps = 2000\n",
    "                for j in range(count_of_optimizing_steps):\n",
    "                    # Optimize.\n",
    "                    sess.run(S_optimizer)\n",
    "                    # Clip and re-feed to sampler.\n",
    "                    sess.run(S_images_op, feed_dict = {S_images_placeholder: \n",
    "                                                       np.clip(sess.run(S_images), -1.0, 1.0)})\n",
    "                    # Stop based on threshold.\n",
    "                    # The threshold is based on real samples' score.\n",
    "                    # Update until the WINN network thinks pseudo-negative samples are quite close to real.\n",
    "                    if sess.run(S_loss) >= thres_:\n",
    "                        break\n",
    "\n",
    "                # Save intermediate negative images in generator.\n",
    "                S_neg_intermediate_images = sess.run(S_images)\n",
    "                [_, height, width, channels] = S_neg_intermediate_images.shape\n",
    "                for j in xrange(batch_size):\n",
    "                    save_unnormalized_image(\n",
    "                        image = unnormalize(S_neg_intermediate_images[j,:,:,:]),  \n",
    "                        path = S_neg_current_iteration_images_path[i * batch_size + j])\n",
    "\n",
    "                # Output information every 100 batches.\n",
    "                if i % 100 == 0:\n",
    "                    log(log_file_path,\n",
    "                          (\"Sampler: Cascade {0}, iteration {1}, batch {2}, \" + \n",
    "                           \"time {3}, S_loss {4}\").format(\n",
    "                           cascade, iteration, i, \n",
    "                           time.time() - start_time, sess.run(S_loss)))\n",
    "\n",
    "            # After current iteration, new negative images will be added into the set of\n",
    "            # negative images. Note that we keep all previous pseudo-negative images\n",
    "            # to prevent the classifier forgetting what it has learned in previous stages\n",
    "            \n",
    "            neg_all_images_path += S_neg_current_iteration_images_path\n",
    "\n",
    "            # Save last batch images in generator training.\n",
    "            S_neg_intermediate_image_path = os.path.join(intermediate_image_root,\n",
    "                'S_cascade_{0}_iteration_{1}.png').format(cascade, iteration)\n",
    "            # In discriminator we save D_batch_images, but here we use \n",
    "            # S_intermediate_images. It is because we always use *_batch_images\n",
    "            # to represent the images we put in the discriminator or generator.\n",
    "            # So G_neg_batch_images should be the \"initial\" images in current \n",
    "            # iteration and S_neg_intermediate_images is the generated images.\n",
    "            save_unnormalized_images(images = unnormalize(S_neg_intermediate_images), \n",
    "                                     size = (sqrt_batch_size, sqrt_batch_size), \n",
    "                                     path = S_neg_intermediate_image_path)\n",
    "            \n",
    "        # Last cascade's generated negative images. More specifically, we only use\n",
    "        # those images generated by last iteration of last cascade.\n",
    "        S_neg_last_cascade_images_path = copy.deepcopy(S_neg_current_iteration_images_path)\n",
    "        \n",
    "        # Save the model.\n",
    "        saver.save(sess, (os.path.join(model_root, 'cascade-{}.model').format(cascade)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-08-24T23:09:40.362Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set dynamic allocation of GPU memory rather than pre-allocation.\n",
    "# Also set soft placement, which means when current GPU does not exist, \n",
    "# it will change into another.\n",
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create computation graph.\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Set GPU number and train.\n",
    "    gpu_number = 0\n",
    "    with tf.device(\"/gpu:{0}\".format(gpu_number)):    \n",
    "        # Training session.\n",
    "        with tf.Session(config = config) as sess:\n",
    "            with tf.variable_scope(\"WINN\", reuse = None):\n",
    "                train(sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "221px",
    "width": "393px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
